{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Segmentation with Breast Cancer Dataset using U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "#import albumentations as A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I used Kaggle Dataset and working in Kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "\n",
    "os.chdir(\"/kaggle/input/augmentedclear\")\n",
    "os.listdir()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## İmport Numpy files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"augmentedData_V2.npy\")\n",
    "label = np.load(\"augmentedLabel_V2.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I have filtered images based on their tags. I used those with a ratio of white area on the label to the whole label greater than 0.005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # n = 10\n",
    "# # veri = data[n,:,:,0]\n",
    "# # etiket = label[n,:,:,0]\n",
    "# # plt.imshow(veri,cmap=\"Greys\")\n",
    "# # plt.figure()\n",
    "# # plt.imshow(etiket,cmap=\"Greys\")\n",
    "\n",
    "# say = 0\n",
    "# for i in range(label.shape[0]):\n",
    "#     if np.sum(label[i,:,:,0])/(512*512)>0.005:\n",
    "#         #print(np.sum(label[i,:,:,0])/(512*512))\n",
    "#         say += 1\n",
    "#         #print(i)\n",
    "#    #plt.imshow(veri,cmap=\"Greys\")\n",
    "# print(say)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adding filtered images to new numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filteredLabel = np.zeros((1238,512,512,2),dtype=\"uint8\")#(172,512,512,2)\n",
    "# filteredData = np.zeros((1238,512,512,1),dtype=\"uint16\")#(172,512,512,1)\n",
    "# j = 0\n",
    "# for i in range(label.shape[0]):\n",
    "#     #print(np.sum(lbl[:,:,0]))\n",
    "#     if (np.sum(label[i,:,:,0])/(512*512))>0.005:\n",
    "#         filteredLabel[j,:,:,:] = label[i,:,:,:]\n",
    "#         filteredData[j,:,:,:] = data[i,:,:,:]\n",
    "#         j += 1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import model_from_json\n",
    "import keras.models as models\n",
    "from keras.metrics import MeanIoU\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape, Permute\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras import Input\n",
    "from keras.layers import concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, BatchNormalization\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unet architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet_512(input_shape=(512, 512, 1),\n",
    "                 num_classes=2):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # 512\n",
    "\n",
    "    down0a = Conv2D(64, (3, 3), padding='same')(inputs)\n",
    "    down0a = BatchNormalization()(down0a)\n",
    "    down0a = Activation('relu')(down0a)\n",
    "    down0a = Conv2D(64, (3, 3), padding='same')(down0a)\n",
    "    down0a = BatchNormalization()(down0a)\n",
    "    down0a = Activation('relu')(down0a)\n",
    "    down0a_pool = MaxPooling2D((2, 2), strides=(2, 2))(down0a)\n",
    "    # 256\n",
    "\n",
    "    down0 = Conv2D(128, (3, 3), padding='same')(down0a_pool)\n",
    "    down0 = BatchNormalization()(down0)\n",
    "    down0 = Activation('relu')(down0)\n",
    "    down0 = Conv2D(128, (3, 3), padding='same')(down0)\n",
    "    down0 = BatchNormalization()(down0)\n",
    "    down0 = Activation('relu')(down0)\n",
    "    down0_pool = MaxPooling2D((2, 2), strides=(2, 2))(down0)\n",
    "    # 128\n",
    "\n",
    "    down1 = Conv2D(256, (3, 3), padding='same')(down0_pool)\n",
    "    down1 = BatchNormalization()(down1)\n",
    "    down1 = Activation('relu')(down1)\n",
    "    down1 = Conv2D(256, (3, 3), padding='same')(down1)\n",
    "    down1 = BatchNormalization()(down1)\n",
    "    down1 = Activation('relu')(down1)\n",
    "    down1_pool = MaxPooling2D((2, 2), strides=(2, 2))(down1)\n",
    "    # 64\n",
    "\n",
    "    down2 = Conv2D(512, (3, 3), padding='same')(down1_pool)\n",
    "    down2 = BatchNormalization()(down2)\n",
    "    down2 = Activation('relu')(down2)\n",
    "    down2 = Conv2D(512, (3, 3), padding='same')(down2)\n",
    "    down2 = BatchNormalization()(down2)\n",
    "    down2 = Activation('relu')(down2)\n",
    "    down2_pool = MaxPooling2D((2, 2), strides=(2, 2))(down2)\n",
    "    # 32\n",
    "\n",
    "    center = Conv2D(1024, (3, 3), padding='same')(down2_pool)\n",
    "    center = BatchNormalization()(center)\n",
    "    center = Activation('relu')(center)\n",
    "    center = Conv2D(1024, (3, 3), padding='same')(center)\n",
    "    center = BatchNormalization()(center)\n",
    "    center = Activation('relu')(center)\n",
    "    # center\n",
    "\n",
    "    up4 = UpSampling2D((2, 2))(center)\n",
    "    up4 = concatenate([down2, up4], axis=3)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchNormalization()(up4)\n",
    "    up4 = Activation('relu')(up4)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchNormalization()(up4)\n",
    "    up4 = Activation('relu')(up4)\n",
    "    # 16\n",
    "\n",
    "    up3 = UpSampling2D((2, 2))(up4)\n",
    "    up3 = concatenate([down1, up3], axis=3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    "    up3 = Activation('relu')(up3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    "    up3 = Activation('relu')(up3)\n",
    "    # 32\n",
    "\n",
    "    up2 = UpSampling2D((2, 2))(up3)\n",
    "    up2 = concatenate([down0, up2], axis=3)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = Activation('relu')(up2)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = Activation('relu')(up2)\n",
    "    # 64\n",
    "\n",
    "    up1 = UpSampling2D((2, 2))(up2)\n",
    "    up1 = concatenate([down0a, up1], axis=3)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = Activation('relu')(up1)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = Activation('relu')(up1)\n",
    "    # 128\n",
    "\n",
    "    # classify\n",
    "    classify = Conv2D(num_classes, (1, 1), activation='sigmoid')(up1)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=classify)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/kaggle/working\")\n",
    "for i in os.listdir():\n",
    "    os.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = get_unet_512()\n",
    "os.chdir(\"/kaggle/working\")\n",
    "\n",
    "model_json = unet.to_json()\n",
    "with open('unet.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I used early stop to avoid to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.mkdir(\"checkpoints\")\n",
    "os.chdir(\"/kaggle/working\")\n",
    "#checkpoint = ModelCheckpoint(fpath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, period=1)\n",
    "\n",
    "fpath='unet_{epoch:02d}_{val_loss:.2f}.hdf5'\n",
    "my_callbacks = [\n",
    "    #patience ile kaç kere değişimin olmayacağını ayarlıyoruz (modelin sabrını ayarlıyoruz), \n",
    "    #monitor ise modeli ne üzerinden izleyeceğimiz. genelde val_loss alınır. acc veya val_acc alınmaz yanlış olur.\n",
    "    EarlyStopping(patience=3,monitor=\"loss\",),\n",
    "    ModelCheckpoint(filepath=fpath,monitor=\"val_loss\",verbose=1, save_best_only=False, save_weights_only=True, period=1),]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dice coef for loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(y_pred, y_true):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1-dice(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=3e-6)\n",
    "unet.compile(loss=dice_loss,optimizer=optimizer, metrics=MeanIoU(num_classes=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataV1 = data/2**16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelV1 = label.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, x_val = dataV1[:1000],dataV1[1000:1100],dataV1[1100:]\n",
    "y_train, y_test, y_val = labelV1[:1000],labelV1[1000:1100],labelV1[1100:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.dtype)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(\"/kaggle/working\")\n",
    "# for i in os.listdir():\n",
    "#     print(i)\n",
    "    \n",
    "# json_file = open(\"unet.json\", 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# unet = model_from_json(loaded_model_json)\n",
    "# #unet.summary()\n",
    "# unet.load_weights(\"unet_25_0.08.hdf5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 100\n",
    "batch_size = 2\n",
    "\n",
    "history = unet.fit(x_train, y_train, \n",
    "                 batch_size=batch_size, \n",
    "                 callbacks=my_callbacks,#ayarladığımız callbacklistesini buraya veriyoruz\n",
    "                 epochs=nb_epoch, verbose=1,\n",
    "                 validation_data=(x_val, y_val)\n",
    "                 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.save_weights(\"model_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results = unet.evaluate(x_test, y_test, batch_size=8)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualization of model accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['mean_io_u'],color=\"green\")\n",
    "plt.plot(history.history['val_mean_io_u'],color=\"blue\")\n",
    "plt.plot(history.history['loss'],color=\"red\")\n",
    "plt.plot(history.history['val_loss'],color=\"orange\")\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val_acc','loss','val_loss'], loc='upper left')\n",
    "isim_fig = \"unet\" + '_fig_acc.png'\n",
    "plt.savefig(isim_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction from test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonuc_img = np.zeros((x_test.shape[0],512,512))\n",
    "deneme = list(range(x_test.shape[0]))\n",
    "for i in deneme:\n",
    "    A = np.zeros((1,512,512,1))\n",
    "    A[0,:,:,:] = x_test[i,:,:,:]\n",
    "    B = unet.predict(A)\n",
    "    C = B[:,:,:,0]\n",
    "    D = C>0.5\n",
    "    D = D[0,:,:]\n",
    "    sonuc_img[i,:,:] = D\n",
    "#     isim = 'sonuc_' + \"unet\" + '_' +str(i) + '.tif'\n",
    "#     cv2.imwrite(isim, 255*D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking whether the predicted images have a zero matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sayac = 0\n",
    "for i in range(x_test.shape[0]):\n",
    "    if np.sum(sonuc_img[i]) == 0:\n",
    "        sayac += 1\n",
    "        #print(\"boş\",i)\n",
    "print(sayac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  visualization of predicted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[12,:,:,0],cmap=\"Greys\")\n",
    "plt.title(\"x_test\")\n",
    "plt.figure()\n",
    "plt.imshow(sonuc_img[12,:,:],cmap=\"Greys\")\n",
    "plt.title(\"predicted\")\n",
    "plt.figure()\n",
    "plt.imshow(y_test[12,:,:,0],cmap=\"Greys\")\n",
    "plt.title(\"y_test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sonuc_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = y_test[:,:,:,0]\n",
    "index = 72\n",
    "sonuc = sonuc_img\n",
    "\n",
    "plt.imshow(label[index],cmap=\"Greys\")\n",
    "plt.figure()\n",
    "plt.imshow(sonuc[index],cmap=\"Greys\")\n",
    "plt.figure()\n",
    "plt.imshow(x_test[index,:,:,0],cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Test (IoU and F1 score are most important metrics for segmentation models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "\n",
    "label = label > 0.5\n",
    "\n",
    "\n",
    "label = label.ravel()\n",
    "\n",
    "\n",
    "sonuc = sonuc > 0.5\n",
    "\n",
    "sonuc = sonuc.ravel()\n",
    "\n",
    "print('Accuracy:')\n",
    "print(np.mean(label == sonuc))\n",
    "\n",
    "print('IoU Score (Jaccard Score):')\n",
    "print(jaccard_score(label, sonuc))\n",
    "\n",
    "print('F1 Score:')\n",
    "print(f1_score(label, sonuc))\n",
    "\n",
    "print('Precision:')\n",
    "print(precision_score(label, sonuc))\n",
    "\n",
    "print('Recall:')\n",
    "print(recall_score(label, sonuc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = []\n",
    "title_list = []\n",
    "print(\"predicted\\tdata\\t\\tlabel\")\n",
    "for i in range(12):\n",
    "    label_list.append(sonuc_img[i+22,:,:])\n",
    "    title_list.append(\"predicted\")\n",
    "    label_list.append(x_test[i+22,:,:,0])\n",
    "    title_list.append(\"data\")\n",
    "    label_list.append(y_test[i+22,:,:,0])\n",
    "    title_list.append(\"label\")\n",
    "  \n",
    "  \n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    #plt.title(title_list[i])\n",
    "    plt.imshow(label_list[i],cmap=\"Greys\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
