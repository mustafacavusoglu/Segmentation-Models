{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Segmentation with Breast Cancer Dataset using FCN Dense Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/kaggle/input/augmentedclear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()\n",
    "data = np.load('augmentedData_V2.npy')\n",
    "label = np.load('augmentedLabel_V2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataV1 = data/2**16\n",
    "labelV1 = label.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, x_val = dataV1[:1000],dataV1[1000:1100],dataV1[1100:]\n",
    "y_train, y_test, y_val = labelV1[:1000],labelV1[1000:1100],labelV1[1100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras.models as models\n",
    "from keras.optimizers import RMSprop,Adam,SGD\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint,TensorBoard\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape, Permute\n",
    "from keras.layers.convolutional import MaxPooling2D, UpSampling2D, Cropping2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Conv3D, Lambda\n",
    "from keras import backend as K\n",
    "from keras.metrics import MeanIoU\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Add\n",
    "from keras.regularizers import l2\n",
    "import json\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for DensNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BN_ReLU_Conv(inputs, n_filters, filter_size=3, dropout_p=0.2):\n",
    "    img = BatchNormalization()(inputs)\n",
    "    img = Activation('relu')(img)\n",
    "    img = Conv2D(n_filters, filter_size, padding='same', kernel_initializer='he_uniform')(img)\n",
    "    if dropout_p != 0.0:\n",
    "        img = Dropout(dropout_p)(img)\n",
    "    return img\n",
    "                            \n",
    "def TransitionDown(inputs, n_filters, dropout_p=0.2):\n",
    "    img = BN_ReLU_Conv(inputs, n_filters, filter_size=1, dropout_p=dropout_p)\n",
    "    img = MaxPooling2D((2,2))(img)\n",
    "    return img\n",
    "\n",
    "def TransitionUp(skip_connection, block_to_upsample, n_filters_keep):\n",
    "    img = Conv2DTranspose(n_filters_keep, kernel_size=3, strides=2, padding='same', kernel_initializer='he_uniform')(block_to_upsample)\n",
    "    img = concatenate([img, skip_connection], axis=-1)\n",
    "    return img\n",
    "\n",
    "def SoftmaxLayer(inputs, n_classes):\n",
    "    img = Conv2D(n_classes, kernel_size=1, padding='same', kernel_initializer='he_uniform')(inputs)\n",
    "#    l = Reshape((-1, n_classes))(l)\n",
    "    img = Activation('sigmoid')(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dense Net Model (FCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tiramisu(\n",
    "        input_shape=(512,512,1),\n",
    "        n_classes = 2,\n",
    "        n_filters_first_conv = 48,\n",
    "        havuz_sayisi = 5,\n",
    "        growth_rate = 12 ,\n",
    "        block_sayisi = [5,5,5,5,5,12,5,5,5,5,5],\n",
    "        dropout_p = 0.2\n",
    "        ):\n",
    "    \n",
    "        \n",
    "    #####################\n",
    "    # First Convolution #\n",
    "    #####################        \n",
    "    inputs = Input(shape=input_shape)\n",
    "    stack = Conv2D(filters=3, kernel_size=3, padding='same', kernel_initializer='he_uniform')(inputs)\n",
    "    n_filters = 3*growth_rate\n",
    "\n",
    "    #####################\n",
    "    # Downsampling path #\n",
    "    #####################     \n",
    "    skip_connection_list = []\n",
    "    \n",
    "    for i in range(havuz_sayisi):\n",
    "        for j in range(block_sayisi[i]):\n",
    "            l = BN_ReLU_Conv(stack, growth_rate, dropout_p=dropout_p)\n",
    "            stack = concatenate([stack, l])\n",
    "            n_filters  += growth_rate\n",
    "        skip_connection_list.append(stack)        \n",
    "        stack = TransitionDown(stack, n_filters, dropout_p)\n",
    "    skip_connection_list = skip_connection_list[::-1]\n",
    "\n",
    "    \n",
    "    #####################\n",
    "    #    Bottleneck     #\n",
    "    #####################     \n",
    "    block_to_upsample=[]\n",
    "    \n",
    "    for j in range(block_sayisi[havuz_sayisi]):\n",
    "        l = BN_ReLU_Conv(stack, growth_rate, dropout_p=dropout_p)\n",
    "        block_to_upsample.append(l)\n",
    "        stack = concatenate([stack,l])\n",
    "    block_to_upsample = concatenate(block_to_upsample)\n",
    "\n",
    "   \n",
    "    #####################\n",
    "    #  Upsampling path  #\n",
    "    #####################\n",
    "    for i in range(havuz_sayisi):\n",
    "        n_filters_keep = growth_rate * block_sayisi[havuz_sayisi + i ]\n",
    "        stack = TransitionUp(skip_connection_list[i], block_to_upsample, n_filters_keep)\n",
    "        \n",
    "        block_to_upsample = []\n",
    "        for j in range(block_sayisi[ havuz_sayisi + i + 1 ]):\n",
    "            l = BN_ReLU_Conv(stack, growth_rate, dropout_p=dropout_p)\n",
    "            block_to_upsample.append(l)\n",
    "            stack = concatenate([stack, l])\n",
    "        block_to_upsample = concatenate(block_to_upsample)\n",
    "    \n",
    "    #####################\n",
    "    #  Softmax          #\n",
    "    #####################\n",
    "    output = SoftmaxLayer(stack, n_classes)            \n",
    "    model=Model(inputs = inputs, outputs = output)    \n",
    "    # model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcDensenet = Tiramisu()\n",
    "os.chdir(\"/kaggle/working\")\n",
    "\n",
    "model_json = fcDensenet.to_json()\n",
    "with open('fcDensenet.json', 'w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dice coef for loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(y_pred, y_true):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1-dice(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I used early stop to avoid to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_callbacks = [\n",
    "    EarlyStopping(patience=3,monitor=\"loss\"),\n",
    "    ModelCheckpoint(filepath='DenseUnet_{epoch:02d}_{val_loss:.2f}.hdf5', monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=True, period=1),\n",
    "    #TensorBoard(log_dir='logs'),\n",
    "]\n",
    "\n",
    "\n",
    "optimizerA = Adam(lr=1e-4)\n",
    "optimizerB = RMSprop(lr=5e-5)\n",
    "optimizer = SGD(lr=3e-5)\n",
    "\n",
    "fcDensenet.compile(loss=dice_loss,optimizer=optimizerB, metrics=MeanIoU(num_classes=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 25\n",
    "batch_size = 2\n",
    "\n",
    "\n",
    "history = fcDensenet.fit(x_train, y_train, \n",
    "                 batch_size=batch_size, \n",
    "                 callbacks=my_callbacks,\n",
    "                 epochs=nb_epoch, verbose=1,\n",
    "                 validation_data=(x_val, y_val)\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history) \n",
    "hist_csv_file = 'DenseUnet_history.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = fcDensenet.evaluate(x_test, y_test, batch_size=8)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## visualization of model accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['mean_io_u'],color=\"green\")\n",
    "plt.plot(history.history['val_mean_io_u'],color=\"blue\")\n",
    "plt.plot(history.history['loss'],color=\"red\")\n",
    "plt.plot(history.history['val_loss'],color=\"orange\")\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val_acc','loss','val_loss'], loc='upper left')\n",
    "isim_fig = \"unet\" + '_fig_acc.png'\n",
    "plt.savefig(isim_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction from test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonuc_img = np.zeros((x_test.shape[0],512,512))\n",
    "deneme = list(range(x_test.shape[0]))\n",
    "for i in deneme:\n",
    "    A = np.zeros((1,512,512,1))\n",
    "    A[0,:,:,:] = x_test[i,:,:,:]\n",
    "    B = fcDensenet.predict(A)\n",
    "    C = B[:,:,:,0]\n",
    "    D = C\n",
    "    D = D[0,:,:]\n",
    "    sonuc_img[i,:,:] = D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking whether the predicted images have a zero matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sayac = 0\n",
    "for i in range(x_test.shape[0]):\n",
    "    print(np.sum(sonuc_img[i]))\n",
    "    if np.sum(sonuc_img[i]) == 0:\n",
    "        \n",
    "        sayac += 1\n",
    "        #print(\"boş\",i)\n",
    "print(sayac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  visualization of predicted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = y_test[:,:,:,0]\n",
    "sonuc = sonuc_img\n",
    "\n",
    "index = 10\n",
    "plt.imshow(label[index],cmap=\"Greys\")\n",
    "plt.figure()\n",
    "plt.imshow(sonuc[index],cmap=\"Greys\")\n",
    "plt.figure()\n",
    "plt.imshow(x_test[index,:,:,0],cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Test (IoU and F1 score most important for segmentation models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "\n",
    "label = label > 0.5\n",
    "\n",
    "\n",
    "label = label.ravel()\n",
    "\n",
    "\n",
    "sonuc = sonuc > 0.5\n",
    "\n",
    "sonuc = sonuc.ravel()\n",
    "\n",
    "print('Accuracy:')\n",
    "print(np.mean(label == sonuc))\n",
    "\n",
    "print('IoU Score (Jaccard Score):')\n",
    "print(jaccard_score(label, sonuc))\n",
    "\n",
    "print('F1 Score:')\n",
    "print(f1_score(label, sonuc))\n",
    "\n",
    "print('Precision:')\n",
    "print(precision_score(label, sonuc))\n",
    "\n",
    "print('Recall:')\n",
    "print(recall_score(label, sonuc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = []\n",
    "title_list = []\n",
    "print(\"predicted\\tdata\\t\\tlabel\")\n",
    "for i in range(12):\n",
    "    label_list.append(sonuc_img[i+22,:,:])\n",
    "    title_list.append(\"predicted\")\n",
    "    label_list.append(x_test[i+22,:,:,0])\n",
    "    title_list.append(\"data\")\n",
    "    label_list.append(y_test[i+22,:,:,0])\n",
    "    title_list.append(\"label\")\n",
    "  \n",
    "  \n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    #plt.title(title_list[i])\n",
    "    plt.imshow(label_list[i],cmap=\"Greys\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
